{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccd659b",
   "metadata": {},
   "source": [
    "# Naive Bayes - Class Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767b345",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48c074",
   "metadata": {},
   "source": [
    "## Metadata (Data Dictionary)\n",
    "\n",
    "| No.| Variable | Data Type | Description |\n",
    "|----|----------|-----------|-------------|\n",
    "| 1  | text | string | The text of the tweet |\n",
    "| 2  | sentiment | string | Sentiment category |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a775ff7c",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d8f4b",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('_.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1ba54-57e3-492c-a91a-00f7534b9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the label to binary variable\n",
    "\n",
    "df['sentiment'] = df['sentiment'].map(_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bde77b-2812-47f2-824f-5b7d044686e5",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "Vectorization is like One-hot encoding of sentences.\n",
    "\n",
    "Assuming we have 3 sentences: \"I eat chicken rice\", \"I like cheese burger, \"I drink coffee\".<br>\n",
    "They would be vectorized into the format below.\n",
    "\n",
    "| No.| I | eat | chicken | rice | like | cheese | burger | drink | coffee |\n",
    "|----|---|---|---|---|---|---|---|---|---|\n",
    "| 1  | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| 2  | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 0 | 0 |\n",
    "| 3  | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69b0bd-86ff-4ce4-bf8a-faf754bda9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the vectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e3659-c809-4e66-a155-6398d54c8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d936e1-8e9f-4a73-aff1-2d9a352b0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain vectorized words\n",
    "vectorized_words = cv.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c7314-fb52-4739-95dd-93853c8be3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# They are in the matrix format now\n",
    "vectorized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be7a02-e8f5-44d9-9206-0dd8e920fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the shape of it\n",
    "# This matrix has 5964 rows, which is the size of our dataset, and 3018 columns, which is the total number of words\n",
    "\n",
    "vectorized_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafaaa42-c1d2-4a37-99c5-a5a7bea12d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This attribute records the index of the word\n",
    "# The word \"ABC\" has the index of n, it means it is stored at the n-th column in the matrix\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cba9ff-097d-49f9-b445-d9489459eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we sum the matrix by columns, it will be the count of each word\n",
    "vectorized_words_sum = vectorized_words.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83124ab5-d228-4344-8e52-e1ce8ab817df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a DataFrame to record the index and the count for each word\n",
    "word_count_df = []\n",
    "\n",
    "# Loop over the vacabulary attribute\n",
    "for word in cv.vocabulary_.keys():\n",
    "    index = _\n",
    "    word_count_df.append([index, word, vectorized_words_sum[index]])\n",
    "\n",
    "# Convert it to a DataFrame and sort by index\n",
    "word_count_df = pd.DataFrame(word_count_df, columns=['index', 'word', 'count']).sort_values([_]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff58421-8256-49d4-8575-4e5fc837b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at it\n",
    "word_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b315ff7-6d0c-41e6-92d9-1bb0d9705fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can convert our vectorized matrix to a DataFrame, too, for a better readability\n",
    "vectorized_df = pd.DataFrame(_, columns=word_count_df['word'].to_list())\n",
    "vectorized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9053bc-b209-4eb7-b2b1-cd47aee68e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of words only appeared once\n",
    "# Hence, we can't rely on them to make predictions\n",
    "# We need to words with a minimum set frequency\n",
    "# Let's say, 10\n",
    "\n",
    "frequent_word_df = word_count_df[_]\n",
    "frequent_word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e36100-8e65-4c34-99da-00bc5c03f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we extract those columns of frequent words\n",
    "x = vectorized_df[_]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627c6b9-4b30-4bd2-8027-259569ed7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the label\n",
    "y = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f4aaf-9008-4ef4-86a5-8829bc122f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MultinomialNB from sklearn\n",
    "# This model is good to deal with word count for text classification\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff2a27-6399-423f-b378-b3416486a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(_, _)\n",
    "yhat = model.predict(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75896ff9-8181-4bcc-9d9b-d805e20d7e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2017b00-05d7-44dd-944a-cc17c35ff55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(_, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff61be7-9321-4d35-8909-8b7e481add67",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(_, _)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
