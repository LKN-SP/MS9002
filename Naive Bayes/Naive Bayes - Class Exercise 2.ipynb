{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccd659b",
   "metadata": {},
   "source": [
    "# Naive Bayes - Class Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767b345",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48c074",
   "metadata": {},
   "source": [
    "## Metadata (Data Dictionary)\n",
    "\n",
    "| No.| Variable | Data Type | Description |\n",
    "|----|----------|-----------|-------------|\n",
    "| 1  | fixed acidity | float | Fixed acidity measured |\n",
    "| 2  | volatile acidity | float | Volatile acidity measured|\n",
    "| 3  | citric acid | float | Amount of citric acid |\n",
    "| 4  | residual sugar | float | Amount of residual sugar |\n",
    "| 5  | chlorides | float | Amount of chlorides |\n",
    "| 6  | free sulfur dioxide | float | Amount of free sulfur dioxide |\n",
    "| 7  | total sulfur dioxide | float | Amount of total sulfur dioxide |\n",
    "| 8  | density | float | Density measured |\n",
    "| 9  | pH | float | pH value measured |\n",
    "| 10 | sulphates | float | Amount of sulphates |\n",
    "| 11 | alcohol | float | Amount of alcohol |\n",
    "| 12 | Type | string | Type of Wine (R: Red, W: White) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a775ff7c",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d8f4b",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('_.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefe07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = df['Type'].map({'R': 0, 'W': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa13219-c000-4a06-b303-03cb1860a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8462cd-1103-4d44-86f4-fb138aadb7e3",
   "metadata": {},
   "source": [
    "df.describe() shows 12 columns. That means all columns are in numeric data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eba7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make a conditional box plot for any variable against the label\n",
    "\n",
    "feature = _\n",
    "labels = [0, 1]\n",
    "y = [df[feature][df['Type'] == label] for label in labels]\n",
    "\n",
    "plt.boxplot(y, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the label and the features\n",
    "\n",
    "label = 'Type'\n",
    "features = [feature for feature in df.columns if feature != label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92898a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(_)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010fb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = _\n",
    "train_y = _\n",
    "\n",
    "test_x = _\n",
    "test_y = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e89d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df[_]\n",
    "df_y = df[_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f58a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = _()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(_, _)\n",
    "test_yhat = gnb.predict(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(_, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518664e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_metrics(y, yhat):\n",
    "    # Record the total number of samples\n",
    "    n = len(y)\n",
    "    \n",
    "    # Count the number of correct samples and calculate the accuracy\n",
    "    n_correct = (y == yhat).sum()\n",
    "    accuracy = n_correct / n\n",
    "    \n",
    "    # One way to calculate the error rate\n",
    "    error_rate = 1 - accuracy\n",
    "    \n",
    "    # The other way to calculate the error rate\n",
    "    n_incorrect = (y != yhat).sum()\n",
    "    error_rate = n_incorrect / n\n",
    "    \n",
    "    # Count the number of true positive\n",
    "    TP = ((y == 1) & (yhat == 1)).sum()\n",
    "    \n",
    "    # Count the number of false positive\n",
    "    FP = ((y == 0) & (yhat == 1)).sum()\n",
    "    \n",
    "    # Count the number of true negative\n",
    "    TN = ((y == 0) & (yhat == 0)).sum()\n",
    "    \n",
    "    # Count the number of false negative\n",
    "    FN = ((y == 1) & (yhat == 0)).sum()\n",
    "    \n",
    "    # Calculate sensitivity / specificity / precision / recall\n",
    "    sensitivity = recall = TP / (TP + FN)\n",
    "    specificity = TN / (FP + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    \n",
    "    item = ['Accuracy', 'Error Rate', 'Sensitivity', 'Specificity', 'Precision', 'Recall']\n",
    "    value = accuracy, error_rate, sensitivity, specificity, precision, recall\n",
    "    \n",
    "    df_out = {'Item': item, 'Value': value}\n",
    "    df_out = pd.DataFrame(df_out)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5049c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_metrics(_, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5503b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
