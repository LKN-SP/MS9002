{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d7444d",
   "metadata": {},
   "source": [
    "# Decision Trees - Class Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecd1fb",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Cleveland Heart Disease Dataset, hosted by the UCI Machine Learning Repository, is a cornerstone in the field of medical informatics for predicting the presence of heart disease in patients. This dataset comprises 303 individual records, each described by 14 variables, including age, sex, chest pain type, resting blood pressure, serum cholesterol levels, fasting blood sugar, resting electrocardiographic results, maximum heart rate achieved, exercise-induced angina, and others. The target variable indicates the presence or absence of heart disease.\n",
    "\n",
    "Originally contributed by the Cleveland Clinic Foundation, this dataset has been widely used for benchmarking machine learning models in binary classification tasks, where the objective is to accurately predict whether or not a patient has heart disease based on their medical measurements. It serves not only as a practical dataset for predictive modeling but also as a valuable resource for exploring machine learning techniques in healthcare applications.\n",
    "\n",
    "Our goal is to build a decision tree a model to predict whether a patient has heart disease or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca375494",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "| Variables     | Description                                                 |\n",
    "|---------------|-------------------------------------------------------------|\n",
    "| age           | Age of patient (in years)                                   |\n",
    "| sex           | Gender of patient (0 = female; 1 = male)                    |\n",
    "| cp            | Chest pain type (1: typical angina; 2: atypical angina; 3: non-anginal pain; 4: asymptomatic) |\n",
    "| restbps       | Resting blood pressure on admission to hospital (in mmHg)   |\n",
    "| chol          | Serum cholesterol (in mg/dl)                                |\n",
    "| fbs           | Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)       |\n",
    "| restecg       | Resting electrocardiographic results (values 0, 1, 2)       |\n",
    "| thalach       | Maximum heart rate achieved                                 |\n",
    "| exang         | Exercise induced angina (1 = yes; 0 = no)                   |\n",
    "| oldpeak       | ST depression induced by exercise relative to rest          |\n",
    "| slope         | Slope of the peak exercise ST segment (values 1, 2, 3)      |\n",
    "| ca            | Number of major vessels colored by fluoroscopy (0 to 4)     |\n",
    "| thal          | 3 = normal; 6 = fixed defect; 7 = reversible defect         |\n",
    "| target        | Presence (Yes) or absence (No) of heart disease             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2317145",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a739e",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0159c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97c319",
   "metadata": {},
   "source": [
    "## Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d3713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values = df._\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09afdc88",
   "metadata": {},
   "source": [
    "We observe that there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce801c",
   "metadata": {},
   "source": [
    "## One-hot Encoding for Multiclass Variables\n",
    "\n",
    "To prevent the potential problem of *spurious ordering* in multiclass variables with ```K>2``` classes, we will apply one-hot encoding to transform all of them into separate ```K-1``` binary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75774836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize encoder\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "# Declare all multiclass variables with K>2 classes\n",
    "multiclass_columns = [_]\n",
    "\n",
    "# Encode multiclass variables with K>2 classes\n",
    "for column in multiclass_columns:\n",
    "    encoded_result = encoder.fit_transform(df[[column]])\n",
    "    encoded_df = pd.DataFrame(encoded_result, columns=encoder.get_feature_names_out([column]))\n",
    "    # Drop original column and concatenate the new one-hot encoded DataFrame\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee7302",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737bcc0d-e129-4ae9-9ff6-5fd0245cb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = _\n",
    "excluded_columns = [label]\n",
    "features = [feature for feature in list(df) if feature not in excluded_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7556bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify split parameters\n",
    "random_seed = 9002\n",
    "test_size = 0.2\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of train set: ', len(X_train))\n",
    "print('Size of test set: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c1a2e",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac02b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify model parameters\n",
    "criterion = 'gini'\n",
    "min_samples_leaf = 40\n",
    "\n",
    "# Build model\n",
    "model = DecisionTreeClassifier(_)\n",
    "\n",
    "# Fit model on training data\n",
    "model.fit(_)\n",
    "\n",
    "# Visualize the decision tree\n",
    "feature_names = X_train.columns.tolist()\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot_tree(model, filled=True, feature_names=feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47063681",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852049c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test data\n",
    "y_pred = model.predict(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test accuracy\n",
    "accuracy_test = accuracy_score(_)\n",
    "print(f\"Test accuracy: {accuracy_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4310e4",
   "metadata": {},
   "source": [
    "## Model Improvement\n",
    "\n",
    "To improve the model, we will experiment with two hyperparameters:\n",
    "* ```criterion```\n",
    "* ```min_samples_leaf```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af157cae",
   "metadata": {},
   "source": [
    "We will first define the hyperparameter grid for ```criterion``` and ```min_samples_leaf```, which contains values for these two hyperparameters that we will be experimenting with. Then, we will use ```GridSearchCV``` to perform a grid search to obtain the optimal values of the two hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ebf4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_leaf': [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e620226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search with 10-fold cross-validation\n",
    "model = DecisionTreeClassifier()\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=9002)\n",
    "grid_search = GridSearchCV(_)\n",
    "grid_search.fit(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040030e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best params and best validation score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(f\"Best average cross-validation score: {grid_search.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eddf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit optimal model using best params found above\n",
    "optimal_model = grid_search.best_estimator_\n",
    "\n",
    "# Visualize the optimal decision tree\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot_tree(optimal_model, filled=True, feature_names=feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05dba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the optimal model on the test data\n",
    "y_test_pred = optimal_model.predict(_)\n",
    "test_accuracy = accuracy_score(_)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix for optimal model\n",
    "cm = confusion_matrix(_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117fb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
