{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73eb6d2",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852135c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e38c9",
   "metadata": {},
   "source": [
    "# 1.0 Get to know Series and DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911ec27",
   "metadata": {},
   "source": [
    "## 1.1 What is pandas.Series?\n",
    "<b><font color=\"orange\" size=5>★</font> New Function:</b> pandas.Series()\n",
    "\n",
    "A pandas.Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index.\n",
    "\n",
    "Here's a simple example to illustrate a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90988a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 3, 5, 7, 9]\n",
    "series = pd.Series(data)\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e4636",
   "metadata": {},
   "source": [
    "In this output, the left column (0, 1, ..., 4) represents <b><font color=\"#AA0000\">the indices</font></b>, and the right column (1, 3, ..., 9) represents <b><font color=\"#AA0000\">the values</font></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3516f1a",
   "metadata": {},
   "source": [
    "## 1.2 What is pandas.DataFrame?\n",
    "<b><font color=\"orange\" size=5>★</font> New Function:</b> pandas.DataFrame()\n",
    "\n",
    "A pandas.DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). It's basically a table with rows and columns. Columns can be of different types, and it's the most commonly used pandas object.\n",
    "\n",
    "Sometimes a DatFrame may look like a Series when there is only 1 column.\n",
    "\n",
    "Here's a basic example of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [24, 27, 22],\n",
    "        'City': ['New York', 'Boston', 'Los Angeles']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19b9bf1",
   "metadata": {},
   "source": [
    "In this DataFrame, <b>Name</b>, <b>Age</b>, and <b>City</b> are <b><font color=\"#AA0000\">the column headers</font></b>, and the rows are indexed with numbers starting from 0.\n",
    "\n",
    "Both Series and DataFrame are central to data analysis tasks using Pandas. They provide a vast array of functions and methods to efficiently work with structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf020e",
   "metadata": {},
   "source": [
    "## 1.3 Extract a subset from DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93519882",
   "metadata": {},
   "source": [
    "### Preparation - Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [24, 27, 22],\n",
    "        'City': ['New York', 'Boston', 'Los Angeles']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8efe945",
   "metadata": {},
   "source": [
    "### 1.3.1 Extract ONE column from a DataFrame as a Series\n",
    "We can use the column name as the index to extract a column, as a Series object, from a DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aaf8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df['City']\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee83f0b",
   "metadata": {},
   "source": [
    "### 1.3.2 Extract multiple columns from a DataFrame as a DataFrame\n",
    "We can use a list that contains column names as the index to extract a subset from a DataFrame object.<br>\n",
    "The subset will have the same number of rows as the source DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[['Name', 'Age']]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6c318",
   "metadata": {},
   "source": [
    "### 1.3.3 Extract ONE column from a DataFrame as a DataFrame\n",
    "When the list contains only one column name, it will extract a subset with only 1 column.<br>\n",
    "It will look very much like a Series object.<br>\n",
    "Pay extra attention to differentiate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[['City']]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbe751",
   "metadata": {},
   "source": [
    "### 1.3.4 Drop ONE column from a DataFrame\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.drop()\n",
    "\n",
    "We can use DataFrame.drop() function and specify the column name to drop specific columns.\n",
    "\n",
    "The input can be a string to denote the column name.<br>\n",
    "We also need to set axis=1 (if axis=0, it will be dropping rows instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop('City', axis=1)\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e50c1",
   "metadata": {},
   "source": [
    "### 1.3.5 Drop multiple columns from a DataFrame\n",
    "The input can also be a list that contains multiple column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(['Age', 'City'], axis=1)\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe6ea0",
   "metadata": {},
   "source": [
    "### 1.3.6 Extract rows from a DataFrame\n",
    "We can use a range index to extract rows from a DataFrame. It works similar to how to slice a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[1:3]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06554a",
   "metadata": {},
   "source": [
    "We can't just use a single value as the index to slice a DataFrame.<br>\n",
    "When there is no \":\" in the index, a single value will be interpret as the column name and the program would think that you're trying to extract a column.<br>\n",
    "\n",
    "We still need to set a range index even if we're just getting 1 row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[1:2]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c543ee6",
   "metadata": {},
   "source": [
    "### 1.3.7 Extract columns and rows at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ee76f",
   "metadata": {},
   "source": [
    "We can use DataFrame.loc[..., ...] to get a subset.<br>\n",
    "We need to set 2 indices, separated by a comma.<br>\n",
    "\n",
    "The 1st index is the range index to slice rows.<br>\n",
    "The 2nd index is the list of column names to slice columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca85747",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.loc[1:3, ['Age', 'City']]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04cb6b5",
   "metadata": {},
   "source": [
    "We can also use DataFrame.iloc[..., ...] to get a subset.<br>\n",
    "We need to set 2 indices, separated by a comma.<br>\n",
    "\n",
    "The 1st index is the range index to slice rows.<br>\n",
    "The 2nd index is the range index to slice columns.<br>\n",
    "\n",
    "The difference is the 2nd index, where it uses integers, instead of column names, to specify columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96130765",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.iloc[1:3, 1:3]\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7166c",
   "metadata": {},
   "source": [
    "## 1.4 How to read a data file as DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf59d85",
   "metadata": {},
   "source": [
    "### 1.41 Read CSV File with Headers\n",
    "<b><font color=\"orange\" size=5>★</font> New Function:</b> pandas.read_csv()\n",
    "\n",
    "We can use <b><font color=#AA0000>pd.read_csv()</font></b> function to open a \"csv\" file and load it as <b><font color=blue>DataFrame</font></b> object.<br>\n",
    "Pandas automatically uses the first row as column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecfb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Abalone.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07143f88",
   "metadata": {},
   "source": [
    "As you can see above, this Abalone.csv file does not have headers. The data starts from the 1st row.<br>\n",
    "Hence, we need to \"tell\" the function <b>NOT</b> to take the 1st row as the header.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8de500",
   "metadata": {},
   "source": [
    "### 1.4.2 Read CSV File without Headers\n",
    "If the \"csv\" file doesn't contain headers, we can specify this to Pandas by setting <b>header=None</b>, and it will use default integer indices for column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Abalone.csv', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb5597",
   "metadata": {},
   "source": [
    "### 1.4.3 Read CSV File with an Index Column\n",
    "If your CSV file has an index column (a column that should be used as row labels), you can specify this column with the <b>index_col</b> parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('airports.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447ef15",
   "metadata": {},
   "source": [
    "In this case, <b>airport_id</b> is used as the row labels, instead of the default indices starting from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8578c1e",
   "metadata": {},
   "source": [
    "### 1.4.4 Read XLSX File\n",
    "<b><font color=\"orange\" size=5>★</font> New Function:</b> pandas.read_excel()\n",
    "\n",
    "Reading an Excel file is similar, but we use <b>pd.read_excel()</b> instead. Again, Pandas will use the first row for column headers by default.\n",
    "\n",
    "If the Excel file has more than 1 sheets, we will need to specify which sheet to read by setting an input to the <b>sheet_name</b> parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Generalization.xlsx', sheet_name='Sheet1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b44cb",
   "metadata": {},
   "source": [
    "### <font color=darkred><b>Exercise 1</b><font>\n",
    "Extract Row 100-199, Column 4-6 from the Abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6198c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize df just in case they are changed\n",
    "# Do NOT change this cell\n",
    "\n",
    "df = pd.read_csv('Abalone.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for Exercise 1 here\n",
    "\n",
    "df.loc[_, _]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6047ec",
   "metadata": {},
   "source": [
    "## 1.5 Convert to/from DataFrame\n",
    "We can use pd.DataFrame() function to create a DataFrame objectwithout importing it from the file.<br>\n",
    "\n",
    "THe first input is always the data. There are several different data types that we can use to input the data.<br>\n",
    "\n",
    "We can also set an input to \"columns\" argument. It should take a list and it will use the values in the list as the column names.<br>\n",
    "The number of values in the \"columns\" input should be the same as the number of columns we are making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb74a37",
   "metadata": {},
   "source": [
    "### 1.5.1 Creating DataFrame from a 1D list\n",
    "When we use a 1D list as the input. It will just create a DataFrame with only 1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4, 5]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Numbers'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d809d28",
   "metadata": {},
   "source": [
    "### 1.5.2 Create DataFrame from a 2D list\n",
    "We can use a nested list (i.e. lists in a list, or a 2D list) as the input.<br>\n",
    "\n",
    "Each sub-list denotes a row.<br>\n",
    "All the \"sub-lists\" in the list should have equal length, which is the number of columns.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0adeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['Alex', 10],\n",
    "        ['Bob', 12],\n",
    "        ['Clarke', 13]]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bbf74",
   "metadata": {},
   "source": [
    "### 1.5.3 Create DataFrame from a dictionary\n",
    "We can use a dictionary as the input.<br>\n",
    "\n",
    "Each key has a list as its value.<br>\n",
    "All lists should have equal length.<br>\n",
    "Each key denotes the column name.<br>\n",
    "Each list will become a column.<br>\n",
    "\n",
    "When we use a dictionary, we don't need to give an input to \"columns\" argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca047a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Tom', 'Jerry', 'Mickey'],\n",
    "        'Age': [20, 21, 19]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f690327",
   "metadata": {},
   "source": [
    "### <font color=darkred><b>Exercise 2</b><font>\n",
    "Create a DataFrame that looke like this\n",
    "|  | ID | Name |\n",
    "|----------|-----------|-------------|\n",
    "| 0 | 0001 | Adam |\n",
    "| 1 | 0002 | Bruce |\n",
    "| 2 | 0003 | Charles |\n",
    "| 3 | 0004 | David |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for Exercise 2 here\n",
    "\n",
    "# Highlight: ID has leading zeroes so it is string\n",
    "data = {_}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372d4b5",
   "metadata": {},
   "source": [
    "### 1.5.4 Convert a Series to a list\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.to_list()\n",
    "\n",
    "We can use Series.to_list() function to convert a Series object to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Tom', 'Jerry', 'Mickey'],\n",
    "        'Age': [20, 21, 19]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['Name'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa28bd",
   "metadata": {},
   "source": [
    "### 1.5.5 Convert a DataFrame to a list\n",
    "We can use list(df) function to convert a DataFrame object to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3bfd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95071f32",
   "metadata": {},
   "source": [
    "Actually, we can't. It will only return the column names as a list. But we can make good use of it sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d171cbb",
   "metadata": {},
   "source": [
    "### 1.5.6 Convert a DataFrame to a numpy.array\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.to_numpy()\n",
    "\n",
    "We can use DataFrame.to_numpy() function to convert a DataFrame object to a numpy.array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Tom', 'Jerry', 'Mickey'],\n",
    "        'Age': [20, 21, 19]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12f022",
   "metadata": {},
   "source": [
    "# 2.0 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731cd9c",
   "metadata": {},
   "source": [
    "## 2.1 Basic Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91158e2",
   "metadata": {},
   "source": [
    "### Preparation - Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f494bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Car Sales.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c1ace4",
   "metadata": {},
   "source": [
    "### 2.1.1 Display the first/last few rows\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.head()<br>\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.tail()\n",
    "\n",
    "We can use DataFrame.head() function to display the first few rows.\n",
    "By default, it will show the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e33ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac346a0",
   "metadata": {},
   "source": [
    "We can give an integer input to DataFrame.head() to indicate the number of rows to show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18abda22",
   "metadata": {},
   "source": [
    "Similarly, we can use DataFrame.tail() to show the last few rows. It works pretty much the same as DataFrame.head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47367985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d133bda",
   "metadata": {},
   "source": [
    "### 2.1.2 Display the shape of the DataFrame\n",
    "<b><font color=\"orange\" size=5>★</font> New Attribute:</b> pandas.DataFrame.shape\n",
    "\n",
    "We can call DataFrame.shape attribute to get the number of rows and columns in the DataFrame.<br>\n",
    "Take note that DataFrame.shape is an attribute, not a function. So, it is not callable, i.e. do NOT write DataFrame.shape()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a939ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8517ed",
   "metadata": {},
   "source": [
    "DataFrame.shape is a tuple object.<br>\n",
    "The first value is the number of rows and the second value is the number of columns.<br>\n",
    "We can use indices to call the values, or use multiple variables at once to parse the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "n_rows = df.shape[0]\n",
    "n_columns = df.shape[1]\n",
    "print('Method 1:', n_rows, n_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca621f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "n_rows, n_columns = df.shape\n",
    "print('Method 2:', n_rows, n_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab5904",
   "metadata": {},
   "source": [
    "### 2.1.3 Display the data type of each columns\n",
    "<b><font color=\"orange\" size=5>★</font> New Attribute:</b> pandas.DataFrame.dtypes\n",
    "\n",
    "We can use DataFrame.dtypes attribute to get the data type of each column.<br>\n",
    "Take note that DataFrame.dtypes is an attribute so it is not callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad10d1",
   "metadata": {},
   "source": [
    "\"object\" is basically the \"string\" in pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946a5de",
   "metadata": {},
   "source": [
    "### 2.1.4 Display a statistical summary of numerical columns\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.describe()\n",
    "\n",
    "We can use DataFrame.describe() function to display a statistical summary.<br>\n",
    "Take note that columns in \"object\" type will not be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855afdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ec6fb",
   "metadata": {},
   "source": [
    "### 2.1.5 Count the unique values in each column\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.Series.nunique()\n",
    "\n",
    "There is no direct way to display the number of unique values in all columns in one go.<br>\n",
    "Though, we can do it for Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e24b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df['Manufacturer']\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01763350",
   "metadata": {},
   "source": [
    "We can use Series.nunique() function to see the number of unique values in the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f4f94",
   "metadata": {},
   "source": [
    "DataFrame object does not have this method. Hence, if we want to examine the number of unique values in a DataFrame, we have to do it column by column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe12d8b",
   "metadata": {},
   "source": [
    "### <font color=darkred><b>Exercise 3</b><font>\n",
    "Examine the number of unique values in each column.<br>\n",
    "<i>Hint: Use for loop.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13689aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize df just in case they are changed\n",
    "# Do NOT change this cell\n",
    "\n",
    "df = pd.read_csv('Car Sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for Exercise 3 here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab41433",
   "metadata": {},
   "source": [
    "## 2.2 Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d246e3",
   "metadata": {},
   "source": [
    "### Preparation - Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie', np.nan],\n",
    "        'Age': [24, np.nan, 22, 27],\n",
    "        'Salary': [70000, 55000, None, 80000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51853258",
   "metadata": {},
   "source": [
    "We have 1 missing value in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464cf07",
   "metadata": {},
   "source": [
    "### 2.2.1 Check for missing values\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.isnull()\n",
    "\n",
    "We can use DataFrame.isnull() function to examine if each value is considered as a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079a9ed",
   "metadata": {},
   "source": [
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.sum()\n",
    "\n",
    "We can use DataFrame.sum() function to determine the sum of each column.<br>\n",
    "When the column is in boolean type (True or False), it will count the number of \"True\" in the column.\n",
    "\n",
    "Hence, we can use DataFrame.isnull().sum() to display the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34776c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fab0d5",
   "metadata": {},
   "source": [
    "### 2.2.2 Drop rows with any missing values\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.dropna()\n",
    "\n",
    "We can use DataFrame.dropna() to drop a row that contains any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.dropna()\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7efba",
   "metadata": {},
   "source": [
    "We have only 1 row left as that is the only complete row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff09bc",
   "metadata": {},
   "source": [
    "### 2.2.3 Drop columns with any missing values\n",
    "We can specify axis=1 in DataFrame.dropna() to drop a column, instead of a row, that contains any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cffe5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.dropna(axis=1)\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbd0fd",
   "metadata": {},
   "source": [
    "We have no column left as each column has 1 missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7557b",
   "metadata": {},
   "source": [
    "### 2.2.4 Drop rows with all values missing\n",
    "We can specify how='all' in DataFrame.dropna().<br>\n",
    "In this case, a row will be dropped only if the row has all values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.dropna(how='all')\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a1a10",
   "metadata": {},
   "source": [
    "There is no row dropped because none of them has all values missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab7842",
   "metadata": {},
   "source": [
    "### 2.2.5 Fill Missing Values with a Specific Value\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.fillna()\n",
    "\n",
    "We can use DataFrame.fillna() to fill the missing values by a specific input value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e42c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df.fillna(0)\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6d2db",
   "metadata": {},
   "source": [
    "If we want to fill different values for different columns, we can input a dictionary instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dce55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df.fillna(value={'Name': 'Unknown', 'Age': 30, 'Salary': 60000})\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01710a2",
   "metadata": {},
   "source": [
    "### 2.2.6 Fill Missing Values by a method\n",
    "We can use several different methods to fill missing values.\n",
    "\n",
    "When we set method='ffill', it will take the last value before each missing values to fill it.<br>\n",
    "However, it will not fill the missing values in the 1st row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffill = df.fillna(method='ffill')\n",
    "df_ffill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb165fb",
   "metadata": {},
   "source": [
    "When we set method='bfill', it will take the next value after each missing values to fill it.<br>\n",
    "However, it will not fill the missing values in the last row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82934759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bfill = df.fillna(method='bfill')\n",
    "df_bfill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c019d",
   "metadata": {},
   "source": [
    "### <font color=darkred><b>Exercise 4</b><font>\n",
    "Fill Missing Values by mean/median and mode\n",
    "For numeric columns, we can fill by the mean or median.<br>\n",
    "For categorical columns, we can fill by the mode.\n",
    "\n",
    "This is a common practice to fill missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23641a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize df just in case they are changed\n",
    "# Do NOT change this cell\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', np.nan],\n",
    "        'Age': [24, np.nan, 22, 27],\n",
    "        'Salary': [70000, 55000, None, 80000]}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e74f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for Exercise 4 here\n",
    "\n",
    "values_for_fillna = {_}\n",
    "df_filled = df.fillna(value=values_for_fillna)\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13546164",
   "metadata": {},
   "source": [
    "## 2.3 Data Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484183b",
   "metadata": {},
   "source": [
    "### Preparation - Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f246675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'ProductID': [101, 102, 103, 104],\n",
    "        'Price': [19.99, 25.50, 8.99, '12.34'],\n",
    "        'Quantity': ['10', '15', '20', '25']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ece71",
   "metadata": {},
   "source": [
    "Although \"Price\" and \"Quantity\" look like numeric columns, but we know they are not, as we set some values as string.<br>\n",
    "We can check the data types by DataFrame.dtypes attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd680b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730a36c",
   "metadata": {},
   "source": [
    "In pandas library, the \"object\" type means string (text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c1209",
   "metadata": {},
   "source": [
    "### 2.3.1 Data Conversion\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.copy()<br>\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.Series.astype()\n",
    "\n",
    "We can use Series.astype() function to convert a Series into a specific data type.<br>\n",
    "We need to set the target data type as the input, for example, str, int or float.\n",
    "\n",
    "We have to set the data conversion column by column, unless we are converting all columns into one type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5601b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a copy of df, so the raw df will not be changed\n",
    "df_copy = df.copy()\n",
    "\n",
    "df_copy['ProductID'] = df_copy['ProductID'].astype(str)\n",
    "df_copy['Price'] = df_copy['Price'].astype(float)\n",
    "df_copy['Quantity'] = df_copy['Quantity'].astype(int)\n",
    "\n",
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a548773",
   "metadata": {},
   "source": [
    "Now, all columns are converted into the correct type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33774a9b",
   "metadata": {},
   "source": [
    "## 2.4 Rename Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a11a02",
   "metadata": {},
   "source": [
    "### Preparation - Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f0fdc",
   "metadata": {},
   "source": [
    "### 2.4.1 Rename specific columns\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.rename()\n",
    "\n",
    "We can use DataFrame.rename() function to rename some specific columns.<br>\n",
    "It takes a dictionary as the input. The keys are the original names and the corresponding values are the new names to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df.rename(columns={'A': 'Alpha', 'B': 'Beta'})\n",
    "df_renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a736772",
   "metadata": {},
   "source": [
    "### 2.4.2 Rename all columns\n",
    "<b><font color=\"orange\" size=5>★</font> New Attribute:</b> pandas.DataFrame.columns\n",
    "\n",
    "We can also overwrite DataFrame.columns by a list.<br>\n",
    "The list should have equal length as the number of columns in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a746938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df.copy()\n",
    "df_renamed.columns = ['X', 'Y', 'Z']\n",
    "df_renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c3d44",
   "metadata": {},
   "source": [
    "## 2.5 Filter data in a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e464d2",
   "metadata": {},
   "source": [
    "### Preparation - Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "        'Age': [25, 30, 35, 40, 22],\n",
    "        'Salary': [70000, 80000, 90000, 60000, 75000],\n",
    "        'Department': ['HR', 'IT', 'Finance', 'Marketing', 'HR']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23723f69",
   "metadata": {},
   "source": [
    "### 2.5.1 Create a boolean Series by comparison operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0908a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Department'] == 'HR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ee4e9",
   "metadata": {},
   "source": [
    "This kind of operators will create a Series in boolean type (True or False)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cceb1af",
   "metadata": {},
   "source": [
    "### 2.5.2 Filter DataFrame by one condition\n",
    "We can use a boolean Series as the index to slice a DataFrame.<br>\n",
    "The resulting DataFrame will keep the rows that correspond to the \"True\" value.<br>\n",
    "Take note that, the boolean Series must have the same length as the number of rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38eaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Department'] == 'HR'\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af41800",
   "metadata": {},
   "source": [
    "We can use \"~\" operator to \"flip\" the boolean value in a Series.<br>\n",
    "If we apply it to the slicing criterion, the resulting DataFrame will keep the rows that correspond to the \"False\" value.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Department'] == 'HR'\n",
    "df_filtered = df[~mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946f297",
   "metadata": {},
   "source": [
    "### 2.5.3 Filter DataFrame by multiple conditions\n",
    "We can use \"&\" operator to join multiple boolean Series by \"AND\" condition.<br>\n",
    "In the resulting boolean series, each value will be \"True\" if both/all corresponding values in joint series are \"True\".\n",
    "\n",
    "Take note that, the joint series need to have equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = df['Age'] <= 30\n",
    "mask2 = df['Salary'] >= 75000\n",
    "mask = mask1 & mask2\n",
    "\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417d83d",
   "metadata": {},
   "source": [
    "We can use \"|\" operator to join multiple boolean Series by \"OR\" condition.<br>\n",
    "In the resulting boolean series, each value will be \"True\" if at least one of the corresponding values in joint series is \"True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d253fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = df['Age'] <= 30\n",
    "mask2 = df['Salary'] >= 75000\n",
    "mask = mask1 | mask2\n",
    "\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc414609",
   "metadata": {},
   "source": [
    "Please take note that, if you are writing multiple conditions in one line, you need to use \"()\" to enclose each condition.<br>\n",
    "Otherwise, there will be an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04074bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Age'] <= 30) | (df['Salary'] >= 75000)\n",
    "\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284b9c7",
   "metadata": {},
   "source": [
    "### 2.5.3 Filter DataFrame by a value range\n",
    "Based on what we have learned, we can simply write it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef6943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Salary'] >= 60000) & (df['Salary'] <= 75000)\n",
    "\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e34ae0",
   "metadata": {},
   "source": [
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.Series.between()\n",
    "\n",
    "Instead, we can use pandas.Series.between() method to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94804e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Salary'].between(60000, 75000)\n",
    "\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f2414d",
   "metadata": {},
   "source": [
    "pandas.Series.between() method works not only on a numeric series, but also a string series as string can be sorted and ranked too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Name'].between('B', 'D')\n",
    "\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed2a2c",
   "metadata": {},
   "source": [
    "When we sort the text, we will have: Alice < B < Bob < Charlie < D < David < Eva.\n",
    "\n",
    "So, 'Bob' and 'Charlie' fall between 'B' and 'D'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6e520",
   "metadata": {},
   "source": [
    "### 2.5.3 Filter DataFrame by a set of values\n",
    "Assuming that we want to extract employees from HR or Marketing department, based on what we have learned, we can simply write it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117300b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Department'] == 'HR') | (df['Department'] == 'Marketing')\n",
    "\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53f5b6",
   "metadata": {},
   "source": [
    "However, we can imagine that, if we want to extract employees from 10 departments, we will need to write 10 joint conditions, which will be long and inefficient.\n",
    "\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.Series.isin()\n",
    "\n",
    "Instead, we can use pandas.Series.isin() method to simplify the command. It will return True if the value is an instance in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d23150",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['Department'].isin(['HR', 'Marketing'])\n",
    "\n",
    "df_filtered = df[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f498ca",
   "metadata": {},
   "source": [
    "## 2.6 Sort values in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d4d05",
   "metadata": {},
   "source": [
    "### Preparation - Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148715ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Name': ['Alice', 'Charlie', 'Bob', 'Eva', 'David'],\n",
    "        'Age': [25, 35, 30, 22, 40],\n",
    "        'Department': ['HR', 'Marketing', 'Sales', 'HR', 'Sales'],\n",
    "        'Salary': [70000, 90000, 80000, 60000, 75000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd48f9",
   "metadata": {},
   "source": [
    "### 2.6.1 Sort by a single column\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.sort_values()\n",
    "\n",
    "We can use DataFrame.sort_values() method to sort values in a DataFrame.<br>\n",
    "We can input the specific column name to the \"by\" argument, which will be the column we use to sort.<br>\n",
    "By default, the sorting will be done in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3509121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='Age')\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df5cfc",
   "metadata": {},
   "source": [
    "Take note that, the indices will be sorted accordingly as well.<br>\n",
    "If we want to reset the index, we can use DataFrame.reset_index() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633cbecd",
   "metadata": {},
   "source": [
    "### 2.6.2 Sort by a column and reset index\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfe23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='Age').reset_index()\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174a5b0",
   "metadata": {},
   "source": [
    "The indices are reset to 0 to 4 in sequence. The previous indices are converted in a new column, called \"index\".\n",
    "If we do not want to keep the previous indices, we can set drop=True in DataFrame.reset_index() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88554c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='Age').reset_index(drop=True)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a87b6c",
   "metadata": {},
   "source": [
    "### 2.6.3 Sort by a single column in descending order\n",
    "We can set ascending=False in DataFrame.sort_values() method so the DataFrame will be sort by the specific column in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='Salary', ascending=False)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11bc19",
   "metadata": {},
   "source": [
    "### 2.6.4 Sort by multiple columns\n",
    "We can input a list of column names to the \"by\" argument.<br>\n",
    "The DataFrame will be sorted by these columns in sequence.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by=['Department', 'Salary'])\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97cd0e",
   "metadata": {},
   "source": [
    "Now, the DataFrame is firstly sorted by \"Department\" in ascending order (A to F), and then by \"Salary\" in ascending order.<br>\n",
    "Apparently, we can set ascending=False to reverse that.\n",
    "\n",
    "What if we want to sort by multiple columns concurrently, but some in ascending order while others in descending order?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff9a41",
   "metadata": {},
   "source": [
    "### 2.6.5 Sort by multiple columns in different sorting methods\n",
    "We can do that by inputting a boolean list to \"ascending\" argument. Each boolean value will determine whether the corresponding column should be sorted in ascending or descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by=['Department', 'Salary'], ascending=[True, False])\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd522241",
   "metadata": {},
   "source": [
    "## 2.7 Aggregate a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b0a9f",
   "metadata": {},
   "source": [
    "### Preparation - Create a DataFrame\n",
    "In term of data manipulation, aggregation means that, we are calculating something out of a group, such as the sum, the average, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ce8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Employee': ['Anna', 'Emma', 'Ethan', 'Gary', 'John', 'Lila', 'Will'],\n",
    "        'Department': ['HR', 'Sales', 'HR', 'Sales', 'HR', 'Sales', 'HR'],\n",
    "        'Seniority': ['Junior', 'Junior',' Senior', 'Senior', 'Senior', 'Junior', 'Junior'],\n",
    "        'Age': [29, 28, 35, 32, 33, 24, 26],\n",
    "        'Salary': [70000, 60000, 80000, 73000, 78000, 55000, 58000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05ae68",
   "metadata": {},
   "source": [
    "### 2.7.1 Aggregate the entire DataFrame\n",
    "There are a few methods that we can use to determine a numeric figure out of a Series/DataFrame.<br>\n",
    "\n",
    "There are a few common examples below:\n",
    "    - DataFrame.mean()\n",
    "    - DataFrame.sum()\n",
    "    - DataFrame.min()\n",
    "    - DataFrame.max()\n",
    "    - ...\n",
    "\n",
    "Those methods can be applied to a Series object, too.\n",
    "\n",
    "However, take note that, when we are trying to use DataFrame.mean(), we need to make sure all columns in the DataFrame are numeric.<br>\n",
    "Hence, sometimes we need to get a subset of the DataFrame first, before we can apply the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean of \"Age\" and \"Salary\"\n",
    "df[['Age', 'Salary']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a843c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the sum of \"Age\" and \"Salary\"\n",
    "df[['Age', 'Salary']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3a056",
   "metadata": {},
   "source": [
    "### 2.7.2 Aggregate by groups\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.groupby()\n",
    "\n",
    "We can use DataFrame.groupby() method to split the DataFrame into groups.<br>\n",
    "Then we can compute those numeric figures per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean of \"Age\" and \"Salary\" per \"Department\"\n",
    "sub_df = df[['Department', 'Age', 'Salary']]\n",
    "sub_df.groupby('Department').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a8560",
   "metadata": {},
   "source": [
    "We can also use a list of multiple columns as the groupby factors. It will create a group per each unique combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb2010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean of \"Age\" and \"Salary\" per \"Department\" and \"Seniority\"\n",
    "sub_df = df[['Department', 'Seniority', 'Age', 'Salary']]\n",
    "sub_df.groupby(['Department', 'Seniority']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ef6ee",
   "metadata": {},
   "source": [
    "### 2.7.3 Aggregate columns in different ways by groups\n",
    "<b><font color=\"orange\" size=5>★</font> New Method:</b> pandas.DataFrame.agg()\n",
    "\n",
    "We can use DataFrame.agg() method to apply different aggregation methods to different columns.<br>\n",
    "\n",
    "Maybe we want to calculate a few numeric figures out of the same column.<br>\n",
    "In this case, we can set a list as the input. The list should contain string to denote the aggregation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5dfb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean and the sum of \"Age\" and of \"Salary\" per \"Department\"\n",
    "sub_df = df[['Department', 'Age', 'Salary']]\n",
    "sub_df.groupby('Department').agg(['mean', 'sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aecc6a",
   "metadata": {},
   "source": [
    "Maybe we want to compute the sum for a column and the average for the other column.<br>\n",
    "In this case, we can set a dictionary as the input.<br>\n",
    "The keys refer to the column names and the values refer to the aggregation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean of \"Age\" and the sum of \"Salary\" per \"Department\"\n",
    "sub_df = df[['Department', 'Age', 'Salary']]\n",
    "sub_df.groupby('Department').agg({'Age': 'mean', 'Salary': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799c57c",
   "metadata": {},
   "source": [
    "Even when we are using a dictionary, we can set some values to a list so a column will be aggregated in few different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff31ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean of \"Age\" and the mean and the sum of \"Salary\" per \"Department\"\n",
    "sub_df = df[['Department', 'Age', 'Salary']]\n",
    "sub_df.groupby('Department').agg({'Age': 'mean', 'Salary': ['mean', 'sum']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac14f4",
   "metadata": {},
   "source": [
    "### <font color=darkred><b>Exercise 5</b><font>\n",
    "Find the min age, the max age, the median salary and the standard deviation of salary per Department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfdbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize df just in case they are changed\n",
    "# Do NOT change this cell\n",
    "\n",
    "data = {'Employee': ['Anna', 'Emma', 'Ethan', 'Gary', 'John', 'Lila', 'Will'],\n",
    "        'Department': ['HR', 'Sales', 'HR', 'Sales', 'HR', 'Sales', 'HR'],\n",
    "        'Seniority': ['Junior', 'Junior',' Senior', 'Senior', 'Senior', 'Junior', 'Junior'],\n",
    "        'Age': [29, 28, 35, 32, 33, 24, 26],\n",
    "        'Salary': [70000, 60000, 80000, 73000, 78000, 55000, 58000]}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for Exercise 5 here\n",
    "\n",
    "sub_df = df[['Department', 'Age', 'Salary']]\n",
    "sub_df.groupby('Department').agg(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97b79b",
   "metadata": {},
   "source": [
    "## 2.8 Merge and concatenate DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db443b",
   "metadata": {},
   "source": [
    "### Preparation - Create multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e832ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {'ID': [1, 2, 3, 4],\n",
    "         'Name': ['Alice', 'Bob', 'Charlie', 'David']}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2aa5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {'ID': [5, 6],\n",
    "         'Name': ['Eva', 'Frank']}\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = {'ID': [4, 5, 6, 7],\n",
    "         'Salary': [70000, 80000, 90000, 60000]}\n",
    "df3 = pd.DataFrame(data3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f6c1a",
   "metadata": {},
   "source": [
    "### 2.8.1 Concatenate DataFrames\n",
    "<b><font color=\"orange\" size=5>★</font> New Function:</b> pandas.concat()\n",
    "\n",
    "We can use pandas.concat() function to join multiple DataFrames vertically.<br>\n",
    "pandas.concate() function takes a list of DataFrames as the input. It can join more than 2 DataFrames at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([df1, df2])\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11760e7f",
   "metadata": {},
   "source": [
    "Take note that, the indices remain the same as how they appear in the separate DataFrames.\n",
    "\n",
    "If we want to reset it, we can set ignore_index=True in pandas.concat() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5380a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df1, df2], ignore_index=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa2769",
   "metadata": {},
   "source": [
    "We can use join multiple DataFrames horizontally by setting axis=1 in pandas.concat() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0332bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([df4, df3], axis=1)\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556baec",
   "metadata": {},
   "source": [
    "We may notice that, if the ID in salary table does not match the ID in name table.<br>\n",
    "In order to align them, we need to use pandas.merge() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fee4a",
   "metadata": {},
   "source": [
    "### 2.8.2 Merge DataFrames\n",
    "<b><font color=\"orange\" size=5>★</font> New Function:</b> pandas.merge()\n",
    "\n",
    "We can use pandas.merge() function to merge DataFrames by a specific key.<br>\n",
    "That means, the rows are joint when they have the same value in the \"key\" column.\n",
    "\n",
    "Take note that, unlike pandas.concat() that can concatenate multiple DataFrames at once, pandas.merge() only processes 2 DataFrames at one time.<br>\n",
    "Hence, it takes the DataFrames separately as 2 inputs, instead of one in the list.<br>\n",
    "They are called the \"left\" table and the \"right\" table.\n",
    "\n",
    "By default, pandas.merge() function takes the first column in each DataFrame as the key. But it would be better to specify them by the \"on\" argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df4, df3, on='ID')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b470ba",
   "metadata": {},
   "source": [
    "We may notice that, only the IDs that appear in both DataFrames are kept.\n",
    "This operation is called \"inner join\".\n",
    "\n",
    "If we want to keep the IDs on the 1st DataFrame (it is also called, the \"left\" table), we can set how='left'.<br>\n",
    "If there is no match, the rows in the \"left\" table will be kept with missing values.\n",
    "This operation is called \"left join\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7541e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df4, df3, on='ID', how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a923141e",
   "metadata": {},
   "source": [
    "Likewise, we can do a \"right join\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe61c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df4, df3, on='ID', how='right')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d9353",
   "metadata": {},
   "source": [
    "If we do not want to drop any row, we can do a \"outer join\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df4, df3, on='ID', how='outer')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bdcb59",
   "metadata": {},
   "source": [
    "### <font color=darkred><b>Exercise 6</b><font>\n",
    "Use airports.csv and flights.csv<br>\n",
    "Find the top 5 cities with the most inbound flights and the top 3 state with the most outbound flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea718a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variable(s) just in case they are changed\n",
    "# Do NOT change this cell\n",
    "\n",
    "airport_df = pd.read_csv('airports.csv')\n",
    "flight_df = pd.read_csv('flights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21696910",
   "metadata": {},
   "source": [
    "<i>Hint: When the left key and the right key are not the same, we need to indicate them separately.<br>\n",
    "We will need to set \"left_on\" and \"right_on\", instead of the \"on\" argument, .</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(_, _, left_on=_, right_on=_)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['city'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e658ee-2a3d-45af-b075-e450b02d05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['state'].value_counts().tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed420e8-8e04-4d23-9934-8ca81fbb0b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
